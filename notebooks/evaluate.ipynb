{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.24.1)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.10.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
      "Requirement already satisfied: backpack-for-pytorch in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
      "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.10/dist-packages (3.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: einops<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from backpack-for-pytorch) (0.8.1)\n",
      "Requirement already satisfied: unfoldNd<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from backpack-for-pytorch) (0.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy seaborn matplotlib pandas pillow tqdm scikit-learn torch torchvision backpack-for-pytorch opt_einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "N_up = 2\n",
    "nb_dir = '/'.join(os.getcwd().split('/')[:-N_up])\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "N_up = 1\n",
    "nb_dir = '/'.join(os.getcwd().split('/')[:-N_up])\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #0: Define Experimental Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# general\n",
    "device = \"cuda:0\"\n",
    "model_name = \"resnet18\"\n",
    "dataset = \"MNIST\"\n",
    "\n",
    "train_batch_size = 256 \n",
    "laplace_batch_size = 64 \n",
    "test_batch_size = 64\n",
    "\n",
    "n_test_data = None\n",
    "rotations = [0, 30, 60, 90, 120, 150, 180]\n",
    "n_out = 10\n",
    "loss = \"cross_entropy\"\n",
    "\n",
    "# paths\n",
    "data_dir = \"./data\"\n",
    "root_dir = Path(f\"./{model_name}_{dataset}\")\n",
    "ggn_dir = root_dir / \"ggn.pt\"\n",
    "\n",
    "# subnetwork selection\n",
    "n_weights_subnet = 5000\n",
    "subnet_selection = \"snr\" # \"snr\", \"magnitude\", \"min-wass\", \"random\"\n",
    "layer_weight=None\n",
    "methods=['snr_5K']\n",
    "\n",
    "# prediction\n",
    "pred_lambda = 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time1=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #1: Train or Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nparams: 11163200\n",
      "Use GPU: 0 for training\n",
      "=> loading checkpoint 'resnet18_MNIST/model_best.pth.tar'\n",
      "=> loaded checkpoint 'resnet18_MNIST/model_best.pth.tar' (epoch 22)\n",
      "=> found progress file at 'resnet18_MNIST/stats_array.pkl'\n",
      "=> Loaded progress file at 'resnet18_MNIST/stats_array.pkl'\n",
      "Ntrain: 60000, Nval: 10000\n",
      "0.0 mins elapsed...\n"
     ]
    }
   ],
   "source": [
    "from src.scripts.train_classification import train_loop\n",
    "from src.utils import list_batchnorm_layers, get_n_params, model_to_device, instantiate_model\n",
    "start_time=time.time()\n",
    "\n",
    "model = model_to_device(instantiate_model(model_name, dataset, 0.1), device)\n",
    "bn_layers = list_batchnorm_layers(model)\n",
    "print('Nparams:', get_n_params(model, bn_layers))\n",
    "\n",
    "gpu = 0\n",
    "train_loop(model, dname=dataset, data_dir=data_dir, epochs=20, workers=4, gpu=gpu, resume=str(root_dir / 'model_best.pth.tar'),\n",
    "            weight_decay=1e-4, save_dir=str(root_dir), milestones=[10, 17], MC_samples=1, batch_size=train_batch_size)\n",
    "\n",
    "end_time=time.time()\n",
    "mins_elapsed= round((end_time-start_time)/60, 2)\n",
    "print(f\"{mins_elapsed} mins elapsed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #2: Select Subnetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ntrain: 60000, Nval: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [36:31<00:00,  8.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0.weight                      | remaining =       0 /     576 (  0.00%) | pruned =     576 | shape = torch.Size([64, 1, 3, 3])\n",
      "layer_list.0.conv1.weight           | remaining =      35 /   36864 (  0.09%) | pruned =   36829 | shape = torch.Size([64, 64, 3, 3])\n",
      "layer_list.0.conv2.weight           | remaining =      50 /   36864 (  0.14%) | pruned =   36814 | shape = torch.Size([64, 64, 3, 3])\n",
      "layer_list.1.conv1.weight           | remaining =      27 /   36864 (  0.07%) | pruned =   36837 | shape = torch.Size([64, 64, 3, 3])\n",
      "layer_list.1.conv2.weight           | remaining =      25 /   36864 (  0.07%) | pruned =   36839 | shape = torch.Size([64, 64, 3, 3])\n",
      "layer_list.2.conv1.weight           | remaining =      79 /   73728 (  0.11%) | pruned =   73649 | shape = torch.Size([128, 64, 3, 3])\n",
      "layer_list.2.conv2.weight           | remaining =      74 /  147456 (  0.05%) | pruned =  147382 | shape = torch.Size([128, 128, 3, 3])\n",
      "layer_list.2.downsample.0.weight    | remaining =       8 /    8192 (  0.10%) | pruned =    8184 | shape = torch.Size([128, 64, 1, 1])\n",
      "layer_list.3.conv1.weight           | remaining =     227 /  147456 (  0.15%) | pruned =  147229 | shape = torch.Size([128, 128, 3, 3])\n",
      "layer_list.3.conv2.weight           | remaining =     110 /  147456 (  0.07%) | pruned =  147346 | shape = torch.Size([128, 128, 3, 3])\n",
      "layer_list.4.conv1.weight           | remaining =     567 /  294912 (  0.19%) | pruned =  294345 | shape = torch.Size([256, 128, 3, 3])\n",
      "layer_list.4.conv2.weight           | remaining =     345 /  589824 (  0.06%) | pruned =  589479 | shape = torch.Size([256, 256, 3, 3])\n",
      "layer_list.4.downsample.0.weight    | remaining =      24 /   32768 (  0.07%) | pruned =   32744 | shape = torch.Size([256, 128, 1, 1])\n",
      "layer_list.5.conv1.weight           | remaining =     678 /  589824 (  0.11%) | pruned =  589146 | shape = torch.Size([256, 256, 3, 3])\n",
      "layer_list.5.conv2.weight           | remaining =     298 /  589824 (  0.05%) | pruned =  589526 | shape = torch.Size([256, 256, 3, 3])\n",
      "layer_list.6.conv1.weight           | remaining =     326 / 1179648 (  0.03%) | pruned = 1179322 | shape = torch.Size([512, 256, 3, 3])\n",
      "layer_list.6.conv2.weight           | remaining =     642 / 2359296 (  0.03%) | pruned = 2358654 | shape = torch.Size([512, 512, 3, 3])\n",
      "layer_list.6.downsample.0.weight    | remaining =      73 /  131072 (  0.06%) | pruned =  130999 | shape = torch.Size([512, 256, 1, 1])\n",
      "layer_list.7.conv1.weight           | remaining =     706 / 2359296 (  0.03%) | pruned = 2358590 | shape = torch.Size([512, 512, 3, 3])\n",
      "layer_list.7.conv2.weight           | remaining =     705 / 2359296 (  0.03%) | pruned = 2358591 | shape = torch.Size([512, 512, 3, 3])\n",
      "output_block.weight                 | remaining =       1 /    5120 (  0.02%) | pruned =    5119 | shape = torch.Size([10, 512])\n",
      "====================================================================================================\n",
      "remaining: 5000, pruned: 11158200, total: 11163200, compression rate:    2232.64x  ( 99.96% pruned)\n",
      "36.55 mins elapsed...\n"
     ]
    }
   ],
   "source": [
    "from src.datasets.image_loaders import get_image_loader\n",
    "from src.utils import print_nonzeros\n",
    "from src.masking.masking import random_mask, smallest_magnitude_mask, wasserstein_mask, snr_mask\n",
    "\n",
    "start_time=time.time()\n",
    "# compute subnetwork mask\n",
    "if n_weights_subnet == None:\n",
    "    mask = None\n",
    "\n",
    "elif subnet_selection == \"random\":\n",
    "    mask, index_mask, weight_score_vec = random_mask(model, bn_layers, n_weights_subnet, device=device)\n",
    "\n",
    "elif subnet_selection == \"min-wass\":\n",
    "    train_loader = get_image_loader(dataset, batch_size=train_batch_size, cuda=True, workers=4, \n",
    "                                    distributed=False, data_dir=data_dir)[1]\n",
    "\n",
    "    mask, index_mask, weight_score_vec = wasserstein_mask(model, \n",
    "                                                          bn_layers, \n",
    "                                                          n_weights_subnet, \n",
    "                                                          train_loader, \n",
    "                                                          device,\n",
    "                                                          layer_weight=layer_weight)\n",
    "\n",
    "elif subnet_selection == \"snr\":\n",
    "    train_loader = get_image_loader(dataset, batch_size=train_batch_size, cuda=True, workers=4,\n",
    "                                    distributed=False, data_dir=data_dir)[1]\n",
    "\n",
    "    mask, index_mask, weight_score_vec = snr_mask(model,\n",
    "                                                  bn_layers,\n",
    "                                                  n_weights_subnet,\n",
    "                                                  train_loader,\n",
    "                                                  device)\n",
    "\n",
    "elif subnet_selection == \"magnitude\":\n",
    "    mask, index_mask, weight_score_vec = smallest_magnitude_mask(model, bn_layers, n_weights_subnet)\n",
    "    \n",
    "else:\n",
    "    raise NotImplementedError(\"Supported subnetwork selection methods: snr, random, min-wass, magnitude.\")\n",
    "\n",
    "if mask is not None:\n",
    "    # print mask information\n",
    "    print_nonzeros(mask)\n",
    "\n",
    "end_time=time.time()\n",
    "mins_elapsed= round((end_time-start_time)/60, 2)\n",
    "print(f\"{mins_elapsed} mins elapsed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask, index_mask, weight_score_vec = wasserstein_mask(model, bn_layers, n_weights_subnet, train_loader, device, weight_score_vec=weight_score_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #3: Do Linearized Laplace Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Laplace model from disk...\n",
      "0.01 mins elapsed...\n"
     ]
    }
   ],
   "source": [
    "from src.laplace.laplace import Laplace\n",
    "from src.datasets.image_loaders import get_image_loader\n",
    "\n",
    "start_time=time.time()\n",
    "# instantiate Laplace model\n",
    "laplace_dir = root_dir / f\"laplace.pth.tar\"\n",
    "laplace_model = Laplace(model, \n",
    "                        mask=mask, \n",
    "                        index_mask=index_mask, \n",
    "                        save_path=laplace_dir, \n",
    "                        device=device, \n",
    "                        loss=loss, \n",
    "                        n_out=n_out)\n",
    "\n",
    "# load or fit Hessian approximation\n",
    "if ggn_dir.exists():\n",
    "    print(\"Loading GGN from disk...\")\n",
    "    laplace_model.H = torch.load(ggn_dir)\n",
    "\n",
    "elif laplace_dir.exists():\n",
    "    print(\"Loading Laplace model from disk...\")\n",
    "    laplace_model.load()\n",
    "\n",
    "else:\n",
    "    print(f\"Computing Hessian/GGN...\")\n",
    "    train_loader = get_image_loader(dataset, batch_size=laplace_batch_size, cuda=True, workers=2, distributed=False, data_dir=data_dir)[1]\n",
    "    laplace_model.fit_laplace(train_loader)\n",
    "\n",
    "end_time=time.time()\n",
    "mins_elapsed= round((end_time-start_time)/60, 2)\n",
    "print(f\"{mins_elapsed} mins elapsed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step #4: Make OOD Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "results_ood_path = root_dir / \"results_ood.npy\"\n",
    "\n",
    "if results_ood_path.exists():\n",
    "    results_dict_ood = np.load(results_ood_path, allow_pickle=True).item()\n",
    "else:\n",
    "    results_dict_ood = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions for snr_5K...\n",
      "Ntrain: 60000, Nval: 10000\n",
      "Computing covariance matrix...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee83513b240470bb33d04b93a30b662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/backpack/extensions/backprop_extension.py:106: UserWarning: Extension saving to grad_batch does not have an extension for Module <class 'src.models.img_resnets.ResNet'> although the module has parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/backpack/extensions/backprop_extension.py:106: UserWarning: Extension saving to grad_batch does not have an extension for Module <class 'src.models.img_resnets.BasicBlock'> although the module has parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing covariance matrix...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca4a76190c44b61b4040d9700b8bead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.86 mins elapsed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/subnetwork_inference/src/evaluation/utils.py:61: RuntimeWarning: Mean of empty slice.\n",
      "  reference = np.array([expanded_preds[bin_idxs == nbin].mean() for nbin in range(n_bins)])\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "from src.evaluation.evaluate_ood import evaluate_laplace_ood\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "# compute error, log-likelihood, Brier score and ECE on shifted test data\n",
    "for method in methods:\n",
    "    if method in results_dict_ood:\n",
    "        continue\n",
    "    elif method not in results_dict_ood:\n",
    "        results_dict_ood[method] = {}\n",
    "\n",
    "    print(f\"Computing predictions for {method}...\")\n",
    "\n",
    "    results_dict_ood[method] = evaluate_laplace_ood(laplace_model, dataset, data_dir, target_dataset=\"Fashion\",\n",
    "                                                     batch_size=test_batch_size, λ=pred_lambda, n_test_data=n_test_data)\n",
    "\n",
    "# save result dictionary\n",
    "np.save(results_ood_path, results_dict_ood)\n",
    "\n",
    "end_time=time.time()\n",
    "mins_elapsed= round((end_time-start_time)/60, 2)\n",
    "print(f\"{mins_elapsed} mins elapsed...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotation-wise Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = root_dir / \"results.npy\"\n",
    "if results_path.exists():\n",
    "    results_dict = np.load(results_path, allow_pickle=True).item()\n",
    "else:\n",
    "    results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions for snr_5K at rotation=0...\n",
      "Ntrain: 60000, Nval: 10000\n",
      "Computing covariance matrix...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb0c9e7101047628b45c7d31192a8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/backpack/extensions/backprop_extension.py:106: UserWarning: Extension saving to grad_batch does not have an extension for Module <class 'src.models.img_resnets.ResNet'> although the module has parameters\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/backpack/extensions/backprop_extension.py:106: UserWarning: Extension saving to grad_batch does not have an extension for Module <class 'src.models.img_resnets.BasicBlock'> although the module has parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions for snr_5K at rotation=30...\n",
      "Computing covariance matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/subnetwork_inference/src/evaluation/utils.py:61: RuntimeWarning: Mean of empty slice.\n",
      "  reference = np.array([expanded_preds[bin_idxs == nbin].mean() for nbin in range(n_bins)])\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b45c8d8e2fb4a8d96f9ce30d21f22ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions for snr_5K at rotation=60...\n",
      "Computing covariance matrix...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5d5baec0634b68a88bcce50a95f009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions for snr_5K at rotation=90...\n",
      "Computing covariance matrix...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81be72441ae74e0996be4dc3202eb37a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions for snr_5K at rotation=120...\n",
      "Computing covariance matrix...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf454b0344624980a058a30288c3da90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions for snr_5K at rotation=150...\n",
      "Computing covariance matrix...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba5c5c1fd68d479a9334fe7d9d1b4a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing predictions for snr_5K at rotation=180...\n",
      "Computing covariance matrix...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c40fab0823145f292353217bbdadf2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.96 mins elapsed...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.evaluation.evaluate_laplace import evaluate_laplace\n",
    "from src.evaluation.evaluate_baselines import evaluate_map\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "# compute error, log-likelihood, Brier score and ECE on shifted test data\n",
    "for method in methods:\n",
    "    for rot in rotations:\n",
    "        if method in results_dict and rot in results_dict[method]:\n",
    "            continue\n",
    "        elif method not in results_dict:\n",
    "            results_dict[method] = {}\n",
    "\n",
    "        print(f\"Computing predictions for {method} at rotation={rot}...\")\n",
    "        \n",
    "        if method == \"MAP\":\n",
    "            results_dict[method][rot] = evaluate_map(model, dataset, data_dir, device, loss, corruption=None,\n",
    "                                                    rotation=rot, batch_size=test_batch_size, n_test_data=n_test_data)\n",
    "        else:\n",
    "            results_dict[method][rot] = evaluate_laplace(laplace_model, dataset, data_dir, corruption=None, rotation=rot, \n",
    "                                                        batch_size=test_batch_size, λ=pred_lambda, n_test_data=n_test_data)\n",
    "\n",
    "# save result dictionary\n",
    "np.save(results_path, results_dict)\n",
    "\n",
    "end_time=time.time()\n",
    "mins_elapsed= round((end_time-start_time)/60, 2)\n",
    "print(f\"{mins_elapsed} mins elapsed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>rotation</th>\n",
       "      <th>err</th>\n",
       "      <th>ll</th>\n",
       "      <th>brier</th>\n",
       "      <th>ece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>-0.017919</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>0.001297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAP</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>-0.317241</td>\n",
       "      <td>0.142648</td>\n",
       "      <td>0.039864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAP</td>\n",
       "      <td>60</td>\n",
       "      <td>0.6238</td>\n",
       "      <td>-3.433685</td>\n",
       "      <td>1.032552</td>\n",
       "      <td>0.459178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MAP</td>\n",
       "      <td>90</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>-6.069594</td>\n",
       "      <td>1.399243</td>\n",
       "      <td>0.640741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MAP</td>\n",
       "      <td>120</td>\n",
       "      <td>0.7754</td>\n",
       "      <td>-6.582309</td>\n",
       "      <td>1.305964</td>\n",
       "      <td>0.593431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>snr_5K</td>\n",
       "      <td>60</td>\n",
       "      <td>0.6209</td>\n",
       "      <td>-2.922373</td>\n",
       "      <td>0.990425</td>\n",
       "      <td>0.420624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>snr_5K</td>\n",
       "      <td>90</td>\n",
       "      <td>0.8355</td>\n",
       "      <td>-5.115520</td>\n",
       "      <td>1.341547</td>\n",
       "      <td>0.597469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>snr_5K</td>\n",
       "      <td>120</td>\n",
       "      <td>0.7765</td>\n",
       "      <td>-5.563317</td>\n",
       "      <td>1.261235</td>\n",
       "      <td>0.555133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>snr_5K</td>\n",
       "      <td>150</td>\n",
       "      <td>0.6279</td>\n",
       "      <td>-5.174534</td>\n",
       "      <td>1.032490</td>\n",
       "      <td>0.446203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>snr_5K</td>\n",
       "      <td>180</td>\n",
       "      <td>0.5493</td>\n",
       "      <td>-5.657732</td>\n",
       "      <td>0.950759</td>\n",
       "      <td>0.424634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     method  rotation     err        ll     brier       ece\n",
       "0       MAP         0  0.0055 -0.017919  0.008828  0.001297\n",
       "1       MAP        30  0.0916 -0.317241  0.142648  0.039864\n",
       "2       MAP        60  0.6238 -3.433685  1.032552  0.459178\n",
       "3       MAP        90  0.8357 -6.069594  1.399243  0.640741\n",
       "4       MAP       120  0.7754 -6.582309  1.305964  0.593431\n",
       "..      ...       ...     ...       ...       ...       ...\n",
       "128  snr_5K        60  0.6209 -2.922373  0.990425  0.420624\n",
       "129  snr_5K        90  0.8355 -5.115520  1.341547  0.597469\n",
       "130  snr_5K       120  0.7765 -5.563317  1.261235  0.555133\n",
       "131  snr_5K       150  0.6279 -5.174534  1.032490  0.446203\n",
       "132  snr_5K       180  0.5493 -5.657732  0.950759  0.424634\n",
       "\n",
       "[133 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Create a list to hold the rows of the DataFrame\n",
    "rows_list = []\n",
    "\n",
    "for method, rotations_data in results_dict.items():\n",
    "    for rotation, metrics in rotations_data.items():\n",
    "        row_dict = {'method': method, 'rotation': rotation}\n",
    "        row_dict.update(metrics)  # Add 'err', 'll', 'brier', 'ece'\n",
    "        rows_list.append(row_dict)\n",
    "\n",
    "df = pd.DataFrame(rows_list)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved as: results/Results_20250505_161435.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"results/Results_{timestamp}.csv\"\n",
    "df.to_csv('Results_.csv') # always overwrites this one, contains latest\n",
    "df.to_csv(filename, index=False) # keeps track of all files\n",
    "print(f\"Results saved as: {filename}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation completed...\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation completed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 67.52 mins elapsed...\n"
     ]
    }
   ],
   "source": [
    "end_time1=time.time()\n",
    "mins_elapsed= round((end_time1-start_time1)/60, 2)\n",
    "print(f\"Total {mins_elapsed} mins elapsed...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>rotation</th>\n",
       "      <th>err</th>\n",
       "      <th>ll</th>\n",
       "      <th>brier</th>\n",
       "      <th>ece</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>min_wass_5K</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>-0.012224</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>0.002052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>min_wass_5K</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>-0.260640</td>\n",
       "      <td>0.126127</td>\n",
       "      <td>0.025123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>min_wass_5K</td>\n",
       "      <td>60</td>\n",
       "      <td>0.6309</td>\n",
       "      <td>-2.978986</td>\n",
       "      <td>1.001125</td>\n",
       "      <td>0.433694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min_wass_5K</td>\n",
       "      <td>90</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>-5.068996</td>\n",
       "      <td>1.326677</td>\n",
       "      <td>0.594812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>min_wass_5K</td>\n",
       "      <td>120</td>\n",
       "      <td>0.7751</td>\n",
       "      <td>-5.309010</td>\n",
       "      <td>1.253082</td>\n",
       "      <td>0.557794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>min_wass_5K</td>\n",
       "      <td>150</td>\n",
       "      <td>0.6206</td>\n",
       "      <td>-5.596350</td>\n",
       "      <td>1.060961</td>\n",
       "      <td>0.477014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>min_wass_5K</td>\n",
       "      <td>180</td>\n",
       "      <td>0.5729</td>\n",
       "      <td>-6.082541</td>\n",
       "      <td>1.013237</td>\n",
       "      <td>0.470645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        method  rotation     err        ll     brier       ece\n",
       "0  min_wass_5K         0  0.0040 -0.012224  0.005949  0.002052\n",
       "1  min_wass_5K        30  0.0860 -0.260640  0.126127  0.025123\n",
       "2  min_wass_5K        60  0.6309 -2.978986  1.001125  0.433694\n",
       "3  min_wass_5K        90  0.8330 -5.068996  1.326677  0.594812\n",
       "4  min_wass_5K       120  0.7751 -5.309010  1.253082  0.557794\n",
       "5  min_wass_5K       150  0.6206 -5.596350  1.060961  0.477014\n",
       "6  min_wass_5K       180  0.5729 -6.082541  1.013237  0.470645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rows_list = []\n",
    "\n",
    "for method, rotations_data in results_dict.items():\n",
    "    for rotation, metrics in rotations_data.items():\n",
    "        row_dict = {'method': method, 'rotation': rotation}\n",
    "        row_dict.update(metrics)  # Add 'err', 'll', 'brier', 'ece'.'roc_auc'\n",
    "        rows_list.append(row_dict)\n",
    "\n",
    "df = pd.DataFrame(rows_list)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved as: results/Results_20250505_205557.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"results/Results_{timestamp}.csv\"\n",
    "df.to_csv('Results_.csv') # always overwrites this one, contains latest\n",
    "df.to_csv(filename, index=False) # keeps track of all files\n",
    "print(f\"Results saved as: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "metadata": {
   "interpreter": {
    "hash": "9ac6660902323cc88ecf370a9a974dd6d7ecd6ef0563967ae75d2d4cdf0c1f73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
